{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000,)\n",
      "(250000, 30)\n",
      "(250000,)\n",
      "[ 9.08010e+01  2.77870e+01  6.53730e+01  5.59780e+01 -9.99000e+02\n",
      " -9.99000e+02 -9.99000e+02  2.45700e+00  2.06080e+01  1.38624e+02\n",
      "  2.45200e+00  1.40500e+00 -9.99000e+02  2.19770e+01  1.60300e+00\n",
      " -6.43000e-01  5.38810e+01  1.87300e+00  1.79900e+00  1.82090e+01\n",
      "  8.80000e-01  2.19339e+02  1.00000e+00  6.27660e+01  7.78000e-01\n",
      " -2.20900e+00 -9.99000e+02 -9.99000e+02 -9.99000e+02  6.27660e+01]\n"
     ]
    }
   ],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 20)\n"
     ]
    }
   ],
   "source": [
    "tX = np.delete(tX, [4,5,6,12,23,24,25,26,27,28], axis=1)\n",
    "print(tX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Gradient Descent(0/100): loss = 0.171334\n",
      "[ 2.93217078e-02  1.09778103e-02  2.75461137e-02  2.56555112e-02\n",
      "  8.17735432e-04  6.32076088e-03  6.27044785e-02  4.14284700e-04\n",
      "  1.09975024e-04  1.57659702e-02 -4.30361600e-06 -6.59599600e-06\n",
      "  1.56544039e-02 -5.77429600e-06  1.84775960e-05  1.46458931e-02\n",
      "  2.96188400e-06  8.00269744e-02  3.97484000e-04  3.12841054e-02]\n",
      "Gradient Descent(1/100): loss = 926.2079347225275\n",
      "[-4.98549913e+00 -1.34738824e+00 -2.87428987e+00 -3.24335266e+00\n",
      " -7.37916524e-02 -8.50407236e-01 -8.00185245e+00 -4.94650395e-02\n",
      " -1.18987524e-02 -1.55088496e+00  2.55668176e-04  2.08792674e-04\n",
      " -1.78716794e+00  2.27654828e-04 -1.26553270e-03 -1.69042247e+00\n",
      " -3.89037480e-05 -9.97656926e+00 -5.09865133e-02 -4.66379957e+00]\n",
      "Gradient Descent(2/100): loss = 15921031.191912249\n",
      "[ 8.52053587e+02  1.57201463e+02  3.60636769e+02  4.16107969e+02\n",
      "  9.26041040e+00  1.07160689e+02  1.01953732e+03  6.14438797e+00\n",
      "  1.79064826e+00  1.95727885e+02 -3.00368148e-02 -3.21672722e-02\n",
      "  2.24079966e+02 -2.05089942e-02  1.57777990e-01  2.07977939e+02\n",
      "  1.46270783e-02  1.26808156e+03  6.54405904e+00  5.99729471e+02]\n",
      "Gradient Descent(3/100): loss = 285255371637.1149\n",
      "[-1.44872031e+05 -1.79852499e+04 -4.55311497e+04 -5.34207675e+04\n",
      " -1.16596156e+03 -1.35082383e+04 -1.29997551e+05 -7.63638619e+02\n",
      " -2.67634347e+02 -2.47157542e+04  3.41420964e+00  4.97853166e+00\n",
      " -2.81584544e+04  1.24970370e+00 -1.94456884e+01 -2.53040084e+04\n",
      " -3.18395892e+00 -1.61442235e+05 -8.40818732e+02 -7.71233427e+04]\n",
      "Gradient Descent(4/100): loss = 5411833590433348.0\n",
      "[ 2.45342127e+07  1.95716353e+06  5.74494088e+06  6.88511234e+06\n",
      "  1.46595675e+05  1.70017307e+06  1.66089635e+07  9.43075069e+04\n",
      "  4.07087672e+04  3.11860387e+06 -3.67550019e+02 -7.82924546e+02\n",
      "  3.53006806e+06  6.64127738e+01  2.37419037e+03  3.03122080e+06\n",
      "  6.25355785e+02  2.05869095e+07  1.08487951e+05  9.96029163e+06]\n",
      "Gradient Descent(5/100): loss = 1.1022208949341354e+20\n",
      "[-4.14264840e+09 -1.94195563e+08 -7.23968283e+08 -8.91937006e+08\n",
      " -1.83862883e+07 -2.13535979e+08 -2.12766171e+09 -1.15407355e+07\n",
      " -6.29580564e+06 -3.93008008e+08  3.56930940e+04  1.24666882e+05\n",
      " -4.41009465e+08 -4.60174746e+04 -2.85851062e+05 -3.54839175e+08\n",
      " -1.16371394e+05 -2.63069666e+09 -1.40738249e+07 -1.29364424e+09]\n",
      "Gradient Descent(6/100): loss = 2.4237291305304566e+24\n",
      "[ 6.97961164e+11  1.56082588e+10  9.10792142e+10  1.16296181e+11\n",
      "  2.29838261e+09  2.67433392e+10  2.73496639e+11  1.39405856e+09\n",
      "  9.88163190e+08  4.94436502e+10 -2.70292673e+06 -2.00585194e+07\n",
      "  5.48347060e+10  1.21228912e+07  3.37173109e+07  4.00730888e+10\n",
      "  2.09597951e+07  3.37074014e+11  1.83825070e+09  1.69218283e+11]\n",
      "Gradient Descent(7/100): loss = 5.7243502570337795e+28\n",
      "[-1.17401340e+14 -4.72394331e+11 -1.14323303e+13 -1.52860726e+13\n",
      " -2.86015091e+11 -3.33650888e+12 -3.53111182e+13 -1.65237923e+11\n",
      " -1.57083960e+11 -6.20638353e+12  3.80546598e+07  3.25498019e+09\n",
      " -6.77390836e+12 -2.58900344e+09 -3.85401209e+09 -4.26027549e+12\n",
      " -3.69585743e+09 -4.33407384e+13 -2.42144801e+11 -2.23308264e+13]\n",
      "Gradient Descent(8/100): loss = 1.4326473690600526e+33\n",
      "[ 1.97234057e+16 -1.91999983e+14  1.43062338e+15  2.02916035e+15\n",
      "  3.53726641e+13  4.14090787e+14  4.58457155e+15  1.90316202e+13\n",
      "  2.52392046e+13  7.76687224e+14  4.61137184e+10 -5.31839377e+11\n",
      "  8.29268493e+14  5.04255535e+11  4.18405263e+11  4.03116957e+14\n",
      "  6.42366731e+11  5.59771897e+15  3.22281186e+13  2.97861583e+15]\n",
      "Gradient Descent(9/100): loss = 3.7390469337797047e+37\n",
      "[-3.31047648e+18  6.64703213e+16 -1.78287610e+17 -2.72579368e+17\n",
      " -4.33727165e+15 -5.10230881e+16 -5.99428314e+17 -2.09290821e+15\n",
      " -4.09104353e+15 -9.67977169e+16 -1.43659758e+13  8.73741297e+13\n",
      " -1.00226846e+17 -9.33824260e+13 -4.13204115e+13 -2.82120990e+16\n",
      " -1.10526614e+14 -7.27100963e+17 -4.34272443e+15 -4.02403750e+17]\n",
      "Gradient Descent(10/100): loss = 1.0034199575238343e+42\n",
      "[ 5.55261970e+20 -1.54743365e+19  2.20935377e+19  3.71296778e+19\n",
      "  5.25407869e+17  6.22383436e+18  7.90599396e+19  2.11916409e+17\n",
      "  6.67841207e+17  1.19961237e+19  3.24651604e+15 -1.44161110e+16\n",
      "  1.18896729e+19  1.67675701e+16  3.27940685e+15 -2.50820411e+17\n",
      "  1.88805994e+16  9.51214150e+19  5.93676954e+17  5.51741427e+19]\n",
      "Gradient Descent(11/100): loss = 2.740284215164376e+46\n",
      "[-9.30847234e+22  3.14084752e+21 -2.71657014e+21 -5.13874432e+21\n",
      " -6.25379602e+19 -7.48333650e+20 -1.05385051e+22 -1.79409605e+19\n",
      " -1.09638965e+20 -1.47516543e+21 -6.50035043e+17  2.38651867e+18\n",
      " -1.37116574e+21 -2.95055918e+18 -8.82601968e+16  6.71859838e+20\n",
      " -3.20840638e+18 -1.25544774e+22 -8.24960857e+19 -7.69217386e+21]\n",
      "Gradient Descent(12/100): loss = 7.563086898421366e+50\n",
      "[ 1.55986750e+25 -5.95466711e+23  3.30382900e+23  7.23822070e+23\n",
      "  7.24967639e+21  8.80907145e+22  1.42261847e+24  7.82607850e+20\n",
      "  1.80795264e+22  1.79432009e+23  1.22307628e+20 -3.96099976e+20\n",
      "  1.51108922e+23  5.12097521e+20 -4.35730018e+19 -1.92235032e+23\n",
      "  5.43117318e+20  1.67488117e+24  1.16707951e+22  1.09207752e+24]\n",
      "Gradient Descent(13/100): loss = 2.100472924803814e+55\n",
      "[-2.61317068e+27  1.08502667e+26 -3.95527384e+25 -1.03887762e+26\n",
      " -8.05850114e+23 -1.00370397e+25 -1.94883351e+26  1.50239635e+23\n",
      " -2.99167877e+24 -2.14857239e+25 -2.21820975e+22  6.58733145e+22\n",
      " -1.53624904e+25 -8.80231283e+22  1.46832875e+22  4.22807382e+25\n",
      " -9.16776620e+22 -2.26318744e+26 -1.68270729e+24 -1.58035135e+26]\n",
      "Gradient Descent(14/100): loss = 5.85489253807967e+59\n",
      "[ 4.37673468e+29 -1.92797829e+28  4.62575642e+27  1.52016332e+28\n",
      "  8.32544520e+25  1.08371199e+27  2.71430293e+28 -6.07678433e+25\n",
      "  4.96374202e+26  2.51358779e+27  3.92941057e+24 -1.09717831e+25\n",
      "  1.31358456e+27  1.50254776e+25 -3.39368214e+24 -8.35668903e+27\n",
      "  1.54424171e+25  3.10381577e+28  2.47354381e+26  2.33158566e+28]\n",
      "Gradient Descent(15/100): loss = 1.6354515774929527e+64\n",
      "[-7.32923911e+31  3.36869018e+30 -5.21614011e+29 -2.26739595e+30\n",
      " -7.39561864e+27 -1.05863150e+29 -3.84947706e+30  1.46829274e+28\n",
      " -8.25281161e+28 -2.83584236e+29 -6.85126953e+26  1.82958112e+27\n",
      " -6.05525744e+28 -2.55193673e+27  6.86580369e+26  1.56081635e+30\n",
      " -2.59705517e+27 -4.32834978e+30 -3.70575238e+28 -3.50534018e+30]\n",
      "Gradient Descent(16/100): loss = 4.573881103486194e+68\n",
      "[ 1.22718994e+34 -5.81784030e+32  5.53064156e+31  3.44419915e+32\n",
      "  4.09563900e+29  8.15264706e+30  5.56449478e+32 -3.02903798e+30\n",
      "  1.37430748e+31  3.00954539e+31  1.18148327e+29 -3.05360277e+29\n",
      " -1.00437989e+31  4.31820382e+29 -1.29933367e+29 -2.81774294e+32\n",
      "  4.36247631e+29  6.14677956e+32  5.65230921e+30  5.36397811e+32]\n",
      "Gradient Descent(17/100): loss = 1.2800760773492756e+73\n",
      "[-2.05457740e+36  9.96490691e+34 -5.20375665e+33 -5.32028508e+34\n",
      "  3.63629197e+31 -1.52844820e+32 -8.20068446e+34  5.79368648e+32\n",
      " -2.29135787e+33 -2.83710487e+33 -2.02151394e+31  5.09996897e+31\n",
      "  4.23700320e+33 -7.28695464e+31  2.36495799e+31  4.97624392e+34\n",
      " -7.32147960e+31 -8.89759338e+34 -8.76359522e+32 -8.34067409e+34]\n",
      "Gradient Descent(18/100): loss = 3.583942295307885e+77\n",
      "[ 3.43954764e+38 -1.69665647e+37  3.57583274e+35  8.34182154e+36\n",
      " -1.93750282e+34 -1.27897505e+35  1.23161785e+37 -1.06139632e+35\n",
      "  3.82387723e+35  1.96180553e+35  3.43922858e+33 -8.52208943e+33\n",
      " -1.03290829e+36  1.22716549e+34 -4.19923757e+33 -8.65832369e+36\n",
      "  1.22793119e+34  1.31308882e+37  1.37851813e+35  1.31529059e+37]\n",
      "Gradient Descent(19/100): loss = 1.003659023050269e+82\n",
      "[-5.75779264e+40  2.87621561e+39  5.17876781e+36 -1.32489110e+39\n",
      "  4.92609064e+36  4.08471450e+37 -1.88284687e+39  1.89262460e+37\n",
      " -6.38588378e+37  2.46328368e+36 -5.82695048e+35  1.42460476e+36\n",
      "  2.13888265e+38 -2.06347000e+36  7.33355150e+35  1.49089311e+39\n",
      " -2.05840200e+36 -1.97465495e+39 -2.19545041e+37 -2.09919836e+39]\n",
      "Gradient Descent(20/100): loss = 2.811050630720792e+86\n",
      "[ 9.63812280e+42 -4.86018890e+41 -9.10368038e+39  2.12718428e+41\n",
      " -1.03770020e+39 -9.29914186e+39  2.92520671e+41 -3.31483418e+39\n",
      "  1.06701556e+40 -4.88341463e+39  9.84214978e+37 -2.38216305e+38\n",
      " -4.09932310e+40  3.46574712e+38 -1.26608812e+38 -2.54819394e+41\n",
      "  3.44922195e+38  3.02243555e+41  3.53294577e+39  3.38397307e+41]\n",
      "Gradient Descent(21/100): loss = 7.873792547771545e+90\n",
      "[-1.61329980e+45  8.19311280e+43  2.56703867e+42 -3.44590887e+43\n",
      "  2.00688310e+41  1.86832640e+42 -4.60950958e+43  5.73443443e+41\n",
      " -1.78359888e+42  1.38368831e+42 -1.65862978e+40  3.98424677e+40\n",
      "  7.51905444e+42 -5.81597644e+40  2.16803872e+40  4.33190696e+43\n",
      " -5.77813051e+40 -4.70076245e+43 -5.73376189e+41 -5.49978368e+43]\n",
      "Gradient Descent(22/100): loss = 2.205555921696168e+95\n",
      "[ 2.70039473e+47 -1.37870746e+46 -5.61805664e+44  5.62256730e+45\n",
      " -3.70103478e+43 -3.52213614e+44  7.35215624e+45 -9.83383879e+43\n",
      "  2.98234374e+44 -3.03326822e+44  2.79042761e+42 -6.66492069e+42\n",
      " -1.34181541e+45  9.75366144e+42 -3.69070152e+42 -7.33518198e+45\n",
      "  9.67741396e+42  7.41434517e+45  9.36945503e+43  8.99729819e+45]\n",
      "Gradient Descent(23/100): loss = 6.178214061701382e+99\n",
      "[-4.51992798e+49  2.31695192e+48  1.10770032e+47 -9.22702240e+47\n",
      "  6.62777907e+45  6.39549486e+46 -1.18457914e+48  1.67579984e+46\n",
      " -4.98792451e+46  5.98549015e+46 -4.68855759e+44  1.11506405e+45\n",
      "  2.35137850e+47 -1.63493736e+45  6.25573824e+44  1.23844105e+48\n",
      " -1.62054118e+45 -1.18351906e+48 -1.53939580e+46 -1.47957185e+48]\n",
      "Gradient Descent(24/100): loss = 1.730668940826256e+104\n",
      "[ 7.56536341e+51 -3.88980538e+50 -2.06601041e+49  1.52108890e+50\n",
      " -1.16418519e+48 -1.13381204e+49  1.92442680e+50 -2.84267614e+48\n",
      "  8.34370808e+48 -1.11689712e+49  7.87032535e+46 -1.86572278e+47\n",
      " -4.06924551e+49  2.73952274e+47 -1.05698163e+47 -2.08640006e+50\n",
      "  2.71335728e+47  1.90812541e+50  2.54004742e+48  2.44304098e+50]\n",
      "Gradient Descent(25/100): loss = 4.848066654457639e+108\n",
      "[-1.26626192e+54  6.52547729e+52  3.72648837e+51 -2.51641447e+52\n",
      "  2.01803194e+50  1.97796852e+51 -3.14719178e+52  4.80578700e+50\n",
      " -1.39590773e+51  2.01515498e+51 -1.32018219e+49  3.12195454e+49\n",
      "  6.98011416e+51 -4.58910675e+49  1.78168670e+49  3.50926559e+52\n",
      " -4.54269079e+49 -3.10150689e+52 -4.20512522e+50 -4.04671856e+52]\n",
      "Gradient Descent(26/100): loss = 1.3580794851547932e+113\n",
      "[ 2.11940459e+56 -1.09408434e+55 -6.57726984e+53  4.17444672e+54\n",
      " -3.46566285e+52 -3.41225348e+53  5.17407945e+54 -8.10425553e+52\n",
      "  2.33560043e+53 -3.55745631e+53  2.21329756e+51 -5.22432744e+51\n",
      " -1.18972290e+54  7.68582236e+51 -2.99799359e+51 -5.89532468e+54\n",
      "  7.60481360e+51  5.07430802e+54  6.97966608e+52  6.71954775e+54]\n",
      "Gradient Descent(27/100): loss = 3.804371811512905e+117\n",
      "[-3.54733007e+58  1.83359702e+57  1.14393727e+56 -6.93956245e+56\n",
      "  5.91205936e+54  5.83995157e+55 -8.54158977e+56  1.36411347e+55\n",
      " -3.90817380e+55  6.18806658e+55 -3.70909801e+53  8.74284220e+53\n",
      "  2.01842598e+56 -1.28701526e+54  5.03799496e+53  9.89471456e+56\n",
      " -1.27303597e+54 -8.34507755e+56 -1.16078404e+55 -1.11788220e+57]\n",
      "Gradient Descent(28/100): loss = 1.0657157530211729e+122\n",
      "[ 5.93727778e+60 -3.07197041e+59 -1.96920348e+58  1.15549602e+59\n",
      " -1.00363607e+57 -9.93756638e+57  1.41462686e+59 -2.29287811e+57\n",
      "  6.53995182e+57 -1.06533215e+58  6.21388024e+55 -1.46314998e+56\n",
      " -3.41268040e+58  2.15488953e+56 -8.45775602e+55 -1.65959020e+59\n",
      "  2.13095928e+56  1.37799672e+59  1.93342966e+57  1.86242805e+59]\n",
      "Gradient Descent(29/100): loss = 2.985383966743654e+126\n",
      "[-9.93737436e+62  5.14546299e+61  3.36501494e+60 -1.92638298e+61\n",
      "  1.69769176e+59  1.68392962e+60 -2.34869004e+61  3.84995908e+59\n",
      " -1.09444622e+60  1.82058711e+60 -1.04077364e+58  2.44870021e+58\n",
      "  5.75543528e+60 -3.60767139e+58  1.41882704e+58  2.78210766e+61\n",
      " -3.56694400e+58 -2.28264486e+61 -3.22411029e+59 -3.10629217e+61]\n",
      "Gradient Descent(30/100): loss = 8.362944691867682e+130\n",
      "[ 1.66323957e+65 -8.61691904e+63 -5.71963446e+62  3.21460122e+63\n",
      " -2.86411124e+61 -2.84459011e+62  3.90697688e+63 -6.45935144e+61\n",
      "  1.83159242e+62 -3.09467224e+62  1.74290307e+60 -4.09817393e+60\n",
      " -9.68815102e+62  6.03947473e+60 -2.37881330e+60 -4.66205761e+63\n",
      "  5.97045379e+60  3.79043628e+63  5.38116290e+61  5.18525904e+63]\n",
      "Gradient Descent(31/100): loss = 2.3427091721900362e+135\n",
      "[-2.78379414e+67  1.44284337e+66  9.68393578e+64 -5.36814184e+65\n",
      "  4.82240255e+63  4.79417930e+64 -6.50868188e+65  1.08308840e+64\n",
      " -3.06530893e+64  5.23979662e+64 -2.91831653e+62  6.85884845e+62\n",
      "  1.62850978e+65 -1.01099463e+63  3.98664626e+62  7.81004392e+65\n",
      " -9.99334213e+62 -6.30602655e+65 -8.98742380e+63 -8.66117103e+65]\n",
      "Gradient Descent(32/100): loss = 6.562625212596277e+139\n",
      "[ 4.65927968e+69 -2.41568724e+68 -1.63486027e+67  8.96929656e+67\n",
      " -8.10766825e+65 -8.06606674e+66  1.08550541e+68 -1.81528371e+66\n",
      "  5.13012550e+66 -8.84616721e+66  4.88593688e+64 -1.14793318e+65\n",
      " -2.73451170e+67  1.69231612e+65 -6.67907771e+64 -1.30807525e+68\n",
      "  1.67266278e+65  1.05062411e+68  1.50181653e+66  1.44741821e+68]\n",
      "Gradient Descent(33/100): loss = 1.8383866956968385e+144\n",
      "[-7.79830033e+71  4.04415409e+70  2.75407822e+69 -1.49924695e+70\n",
      "  1.36159437e+68  1.35534539e+69 -1.81193238e+70  3.04143416e+68\n",
      " -8.58594361e+68  1.49025196e+69 -8.17956591e+66  1.92125707e+67\n",
      "  4.58799911e+69 -2.83270432e+67  1.11871806e+67  2.19047845e+70\n",
      " -2.79963657e+67 -1.75233181e+70 -2.51054230e+68 -2.41975741e+70]\n",
      "Gradient Descent(34/100): loss = 5.149868712419909e+148\n",
      "[ 1.30521112e+74 -6.76999838e+72 -4.63206887e+71  2.50682980e+72\n",
      " -2.28474749e+70 -2.27519278e+71  3.02645579e+72 -5.09449973e+70\n",
      "  1.43698702e+71 -2.50648505e+71  1.36926547e+69 -3.21556262e+69\n",
      " -7.69318912e+71  4.74145078e+69 -1.87346560e+69 -3.66766834e+72\n",
      "  4.68588487e+69  2.92515718e+72  4.19803856e+70  4.04642307e+72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(35/100): loss = 1.442631663800339e+153\n",
      "[-2.18454650e+76  1.13326030e+75  7.78128920e+73 -4.19257002e+74\n",
      "  3.83139252e+72  3.81654616e+73 -5.05756255e+74  8.53180575e+72\n",
      " -2.40503426e+73  4.21062610e+73 -2.29206085e+71  5.38183589e+71\n",
      "  1.28941619e+74 -7.93622309e+71  3.13697476e+71  6.14043866e+74\n",
      " -7.84294313e+71 -4.88606169e+74 -7.02138076e+72 -6.76804112e+74]\n",
      "Gradient Descent(36/100): loss = 4.041241185893153e+157\n",
      "[ 3.65629822e+78 -1.89694979e+77 -1.30597801e+76  7.01317182e+76\n",
      " -6.42199594e+74 -6.39859834e+75  8.45495110e+76 -1.42862123e+75\n",
      "  4.02524596e+75 -7.06699450e+75  3.83663354e+73 -9.00752411e+73\n",
      " -2.16038741e+76  1.32834506e+74 -5.25207750e+73 -1.02796227e+77\n",
      "  1.31269739e+74  8.16543040e+76  1.17455216e+75  1.13220376e+77]\n",
      "Gradient Descent(37/100): loss = 1.1320720942169149e+162\n",
      "[-6.11958214e+80  3.17519706e+79  2.19040788e+78 -1.17329777e+79\n",
      "  1.07604065e+77  1.07230835e+78 -1.41385387e+79  2.39191312e+77\n",
      " -6.73698603e+77  1.18529573e+78 -6.42190187e+75  1.50758412e+76\n",
      "  3.61874718e+78 -2.22332891e+76  8.79259448e+75  1.72080269e+79\n",
      " -2.19709455e+76 -1.36508263e+79 -1.96506950e+77 -1.89425810e+79]\n",
      "Gradient Descent(38/100): loss = 3.171271337192514e+166\n",
      "[ 1.02424017e+83 -5.31467820e+81 -3.67190709e+80  1.96312145e+81\n",
      " -1.80248014e+79 -1.79646616e+80  2.36478493e+81 -4.00440061e+79\n",
      "  1.12756201e+80 -1.98698941e+80  1.07490187e+78 -2.52323984e+78\n",
      " -6.06038604e+80  3.72128838e+78 -1.47189592e+78 -2.88049360e+81\n",
      "  3.67732305e+78  2.28275849e+81  3.28795453e+79  3.16952237e+81]\n",
      "Gradient Descent(39/100): loss = 8.883676206612402e+170\n",
      "[-1.71427997e+85  8.89563153e+83  6.15305180e+82 -3.28488588e+83\n",
      "  3.01872831e+81  3.00895752e+82 -3.95594082e+83  6.70351011e+81\n",
      " -1.88719340e+82  3.32963061e+82 -1.79915164e+80  4.22314669e+80\n",
      "  1.01479524e+83 -6.22845768e+80  2.46386892e+80  4.82157677e+83\n",
      " -6.15480077e+80 -3.81814883e+83 -5.50181156e+81 -5.30369894e+83]\n",
      "Gradient Descent(40/100): loss = 2.4885824864236685e+175\n",
      "[ 2.86920531e+87 -1.48892114e+86 -1.03077239e+85  5.49691849e+85\n",
      " -5.05487997e+83 -5.03890002e+84  6.61853272e+85 -1.12213812e+84\n",
      "  3.15859017e+84 -5.57788400e+84  3.01135551e+82 -7.06828890e+82\n",
      " -1.69905808e+85  1.04247555e+83 -4.12423398e+82 -8.07050882e+85\n",
      "  1.03013844e+83  6.38727118e+85  9.20682446e+83  8.87537890e+85]\n",
      "Gradient Descent(41/100): loss = 6.971261282446885e+179\n",
      "[-4.80221334e+89  2.49208527e+88  1.72639146e+87 -9.19894265e+87\n",
      "  8.46344588e+85  8.43717322e+86 -1.10742520e+88  1.87834211e+86\n",
      " -5.28653155e+86  9.34215148e+86 -5.04025766e+84  1.18302192e+85\n",
      "  2.84447080e+87 -1.74481687e+85  6.90331663e+84  1.35084314e+88\n",
      " -1.72415664e+85 -1.06863796e+88 -1.54075068e+86 -1.48529374e+88]\n",
      "Gradient Descent(42/100): loss = 1.9528580693489268e+184\n",
      "[ 8.03750459e+91 -4.17110663e+90 -2.89096917e+89  1.53947048e+90\n",
      " -1.41692038e+88 -1.41258303e+89  1.85309608e+90 -3.14406289e+88\n",
      "  8.84807694e+88 -1.56441431e+89  8.43608137e+86 -1.98002910e+87\n",
      " -4.76175549e+89  2.92033569e+87 -1.15548368e+87 -2.26101272e+90\n",
      "  2.88574191e+87  1.78807520e+90  2.57850970e+88  2.48571298e+90]\n",
      "Gradient Descent(43/100): loss = 5.4705375195008705e+188\n",
      "[-1.34524376e+94  6.98132029e+92  4.84053050e+91 -2.57641639e+92\n",
      "  2.37200072e+90  2.36481717e+91 -3.10102192e+92  5.26258091e+90\n",
      " -1.48090548e+91  2.61939991e+91 -1.41197416e+89  3.31398522e+89\n",
      "  7.97098125e+91 -4.88781666e+89  1.93403099e+89  3.78439629e+92\n",
      " -4.82989829e+89 -2.99206631e+92 -4.31534665e+90 -4.16005990e+92]\n",
      "Gradient Descent(44/100): loss = 1.532460613913559e+193\n",
      "[ 2.25154545e+96 -1.16848254e+95 -8.10403138e+93  4.31190561e+94\n",
      " -3.97065685e+92 -3.95872984e+93  5.18954667e+94 -8.80845136e+92\n",
      "  2.47859795e+93 -4.38541159e+93  2.36325833e+91 -5.54663674e+91\n",
      " -1.33426060e+94  8.18081247e+91 -3.23711544e+91 -6.33412778e+94\n",
      "  8.08385064e+91  5.00702256e+94  7.22221756e+92  6.96234820e+94]\n",
      "Gradient Descent(45/100): loss = 4.2928789448947675e+197\n",
      "[-3.76842983e+98  1.95571547e+97  1.35668178e+96 -7.21653749e+96\n",
      "  6.64650571e+94  6.62666517e+95 -8.68495149e+96  1.47433169e+95\n",
      " -4.14844230e+95  7.34154629e+95 -3.95543709e+93  9.28344147e+93\n",
      "  2.23335398e+96 -1.36923349e+94  5.41812815e+93  1.06016745e+97\n",
      " -1.35300195e+94 -8.37925140e+96 -1.20873604e+95 -1.16524597e+97]\n",
      "Gradient Descent(46/100): loss = 1.2025633461272356e+202\n",
      "[ 6.30725127e+100 -3.27331799e+099 -2.27107363e+098  1.20779540e+099\n",
      " -1.11253046e+097 -1.10922517e+098  1.45350158e+099 -2.46766927e+097\n",
      "  6.94327218e+097 -1.22896918e+098  6.62028804e+095 -1.55377588e+096\n",
      " -3.73822473e+098  2.29170253e+096 -9.06854434e+095 -1.77443530e+099\n",
      "  2.26453191e+096  1.40230996e+099  2.02300491e+097  1.95022090e+099]\n",
      "Gradient Descent(47/100): loss = 3.3687383689779745e+206\n",
      "[-1.05564969e+103  5.47860546e+101  3.80160105e+100 -2.02144326e+101\n",
      "  1.86217712e+099  1.85666456e+100 -2.43260328e+101  4.13024452e+099\n",
      " -1.16209987e+100  2.05719987e+100 -1.10804812e+098  2.60056563e+098\n",
      "  6.25700345e+100 -3.83564773e+098  1.51783228e+098  2.96991762e+101\n",
      " -3.79016730e+098 -2.34689009e+101 -3.38583550e+099 -3.26402350e+101]\n",
      "Gradient Descent(48/100): loss = 9.436840259119431e+210\n",
      "[ 1.76684930e+105 -9.16961977e+103 -6.36338678e+102  3.38323786e+103\n",
      " -3.11690027e+101 -3.10769860e+102  4.07129784e+103 -6.91293303e+101\n",
      "  1.94501437e+102 -3.44348663e+102  1.85455558e+100 -4.35258552e+100\n",
      " -1.04727852e+103  6.41976290e+100 -2.54043682e+100 -4.97081414e+103\n",
      "  6.34363591e+100  3.92779672e+103  5.66679346e+101  5.46292484e+103]\n",
      "Gradient Descent(49/100): loss = 2.6435402314808056e+215\n",
      "[-2.95718970e+107  1.53473087e+106  1.06512323e+105 -5.66246616e+105\n",
      "  5.21698290e+103  5.20161334e+104 -6.81394867e+105  1.15703701e+104\n",
      " -3.25538416e+104  5.76381503e+104 -3.10399278e+102  7.28495458e+102\n",
      "  1.75288760e+105 -1.07448192e+103  4.25198581e+102  8.31974096e+105\n",
      " -1.06173972e+103 -6.57371614e+105 -9.48442247e+103 -9.14321746e+105]\n",
      "Gradient Descent(50/100): loss = 7.405344123267267e+219\n",
      "[ 4.94947186e+109 -2.56869671e+108 -1.78280416e+107  9.47720566e+107\n",
      " -8.73196170e+105 -8.70627726e+106  1.14042877e+108 -1.93655965e+106\n",
      "  5.44855996e+106 -9.64748012e+106  5.19518793e+104 -1.21928832e+105\n",
      " -2.93388424e+107  1.79837031e+105 -7.11662863e+104 -1.39248796e+108\n",
      "  1.77704263e+105  1.10021408e+108  1.58739824e+106  1.53029195e+108]\n",
      "Gradient Descent(51/100): loss = 2.0744576129835496e+224\n",
      "[-8.28397023e+111  4.29925497e+110  2.98401880e+109 -1.58619363e+110\n",
      "  1.46150778e+108  1.45721398e+109 -1.90871019e+110  3.24125755e+108\n",
      " -9.11929500e+108  1.61477443e+109 -8.69524059e+106  2.04073213e+107\n",
      "  4.91054426e+109 -3.00994840e+107  1.19112163e+107  2.33062611e+110\n",
      " -2.97425086e+107 -1.84139395e+110 -2.65681937e+108 -2.56124197e+110]\n",
      "Gradient Descent(52/100): loss = 5.811174087851779e+228\n",
      "[ 1.38649465e+114 -7.19570583e+112 -4.99453465e+111  2.65480736e+112\n",
      " -2.44617820e+110 -2.43899802e+111  3.19457966e+112 -5.42494667e+110\n",
      "  1.52630324e+111 -2.70274693e+111  1.45533100e+109 -3.41558902e+109\n",
      " -8.21891681e+111  5.03777669e+109 -1.99359711e+109 -3.90079748e+112\n",
      "  4.97802789e+109  3.08190106e+112  4.44671221e+110  4.28674589e+112]\n",
      "Gradient Descent(53/100): loss = 1.627883070158144e+233\n",
      "[-2.32058704e+116  1.20435208e+115  8.35959323e+113 -4.44334992e+114\n",
      "  4.09423982e+112  4.08223036e+113 -5.34673790e+114  9.07981192e+112\n",
      " -2.55458532e+113  4.52371806e+113 -2.43580114e+111  5.71669771e+111\n",
      "  1.37561927e+114 -8.43176948e+111  3.33670863e+111  6.52880839e+114\n",
      " -8.33176548e+111 -5.15813305e+114 -7.44246266e+112 -7.17472873e+114]\n",
      "Gradient Descent(54/100): loss = 4.560185687173586e+237\n",
      "[ 3.88398486e+118 -2.01573500e+117 -1.39917720e+116  7.43684183e+116\n",
      " -6.85262743e+114 -6.83253732e+115  8.94880736e+116 -1.51969983e+115\n",
      "  4.27562902e+115 -7.57152092e+115  4.07682233e+113 -9.56808131e+113\n",
      " -2.30240089e+116  1.41123228e+114 -5.58468749e+113 -1.09273344e+117\n",
      "  1.39449428e+114  8.63312047e+116  1.24564646e+115  1.20083599e+117]\n",
      "Gradient Descent(55/100): loss = 1.2774439321057586e+242\n",
      "[-6.50065610e+120  3.37375336e+119  2.34184618e+118 -1.24470654e+119\n",
      "  1.14693801e+117  1.14357681e+118 -1.49776007e+119  2.54353934e+117\n",
      " -7.15615328e+117  1.26726895e+118 -6.82341315e+115  1.60141722e+116\n",
      "  3.85356687e+118 -2.36199105e+116  9.34715061e+115  1.82891864e+119\n",
      " -2.33397622e+116 -1.44492110e+119 -2.08484274e+117 -2.00984359e+119]\n",
      "Gradient Descent(56/100): loss = 3.5785012094226165e+246\n",
      "[ 1.08801994e+123 -5.64667987e+121 -3.91960731e+120  2.08327065e+121\n",
      " -1.91964977e+119 -1.91402574e+120  2.50680160e+121 -4.25714914e+119\n",
      "  1.19773092e+120 -2.12106022e+120  1.14204048e+118 -2.68030451e+118\n",
      " -6.44977102e+120  3.95328363e+118 -1.56444188e+118 -3.06107816e+121\n",
      "  3.90639458e+118  2.41836179e+121  3.48941068e+119  3.36388462e+121]\n",
      "Gradient Descent(57/100): loss = 1.0024448497502301e+251\n",
      "[-1.82102755e+125  9.45089550e+123  6.56032943e+122 -3.48678082e+123\n",
      "  3.21294635e+121  3.20353545e+122 -4.19563937e+123  7.12523330e+121\n",
      " -2.00465157e+122  3.55006333e+122 -1.91144271e+120  4.48604663e+120\n",
      "  1.07950652e+123 -6.61664272e+120  2.61842113e+120  5.12335396e+123\n",
      " -6.53816364e+120 -4.04761341e+123 -5.84024524e+121 -5.63015204e+123]\n",
      "Gradient Descent(58/100): loss = 2.808146813377723e+255\n",
      "[ 3.04786817e+127 -1.58180419e+126 -1.09801407e+125  5.83584533e+125\n",
      " -5.37755060e+123 -5.36180213e+124  7.02225665e+125 -1.19255708e+124\n",
      "  3.35520098e+124 -5.94180458e+124  3.19919744e+122 -7.50833141e+122\n",
      " -1.80678271e+125  1.10743280e+123 -4.38247516e+122 -8.57500210e+125\n",
      "  1.09429763e+123  6.77449995e+125  9.77485318e+123  9.42321951e+125]\n",
      "Gradient Descent(59/100): loss = 7.866456221954405e+259\n",
      "[-5.10124098e+129  2.64747861e+128  1.83776311e+127 -9.76749120e+127\n",
      "  9.00047032e+125  8.97411531e+126 -1.17531835e+128  1.99599367e+126\n",
      " -5.61562613e+126  9.94489025e+126 -5.35452286e+124  1.25667532e+125\n",
      "  3.02403170e+127 -1.85351912e+125  7.33498710e+124  1.43520539e+128\n",
      " -1.83153461e+125 -1.13385054e+128 -1.63602345e+126 -1.57717037e+128]\n",
      "Gradient Descent(60/100): loss = 2.2036288557682066e+264\n",
      "[ 8.53798723e+131 -4.43110639e+130 -3.07588912e+129  1.63479154e+130\n",
      " -1.50641853e+128 -1.50200790e+129  1.96713669e+130 -3.34071221e+128\n",
      "  9.39891746e+128 -1.66448983e+129  8.96190823e+126 -2.10330736e+127\n",
      " -5.06135232e+129  3.10224971e+127 -1.22766306e+127 -2.40211524e+130\n",
      "  3.06545395e+127  1.89773097e+130  2.73822353e+128  2.63972081e+130]\n",
      "Gradient Descent(61/100): loss = 6.1730212397570704e+268\n",
      "[-1.42900965e+134  7.41637842e+132  5.14815318e+131 -2.73616202e+132\n",
      "  2.52130802e+130  2.51392644e+131 -3.29240851e+132  5.59137873e+130\n",
      " -1.57310419e+131  2.78587698e+131 -1.49996179e+129  3.52032205e+129\n",
      "  8.47123366e+131 -5.19225998e+129  2.05474997e+129  4.02044006e+132\n",
      " -5.13067450e+129 -3.17624270e+132 -4.58298399e+130 -4.41811942e+132]\n",
      "Gradient Descent(62/100): loss = 1.7292472426445906e+273\n",
      "[ 2.39174471e+136 -1.24128519e+135 -8.61652143e+133  4.57953408e+134\n",
      " -4.21993747e+132 -4.20758353e+133  5.51052541e+134 -9.35833764e+132\n",
      "  2.63291684e+133 -4.66275342e+133  2.51049804e+131 -5.89199071e+131\n",
      " -1.41783812e+134  8.69032669e+131 -3.43905200e+131 -6.72904329e+134\n",
      "  8.58725041e+131  5.31609664e+134  7.67057351e+132  7.39463862e+134]\n",
      "Gradient Descent(63/100): loss = 4.844136946970258e+277\n",
      "[-4.00308197e+138  2.07754893e+137  1.44215612e+136 -7.66479992e+136\n",
      "  7.06294812e+134  7.04227211e+135 -9.22300392e+136  1.56631273e+135\n",
      " -4.40673361e+135  7.80409875e+135 -4.20184058e+133  9.86147121e+133\n",
      "  2.37304817e+136 -1.45450685e+134  5.75596943e+133  1.12624541e+137\n",
      " -1.43725488e+134 -8.89758549e+136 -1.28382956e+135 -1.23764616e+137]\n",
      "Gradient Descent(64/100): loss = 1.356987143441424e+282\n",
      "[ 6.69998983e+140 -3.47721016e+139 -2.41375077e+138  1.28286330e+139\n",
      " -1.18213189e+137 -1.17867144e+138  1.54366069e+139 -2.62155043e+137\n",
      "  7.37558470e+137 -1.30617963e+138  7.03265398e+135 -1.65052220e+136\n",
      " -3.97179113e+138  2.43441962e+136 -9.63381265e+135 -1.88500600e+139\n",
      "  2.40554482e+136  1.48919496e+139  2.14875519e+137  2.07145769e+139]\n",
      "Gradient Descent(65/100): loss = 3.801325453065531e+286\n",
      "[-1.12138258e+143  5.81983423e+141  4.03991711e+140 -2.14713804e+141\n",
      "  1.97854435e+139  1.97275270e+140 -2.58363611e+141  4.38771022e+139\n",
      " -1.23445741e+140  2.18616499e+140 -1.17706087e+138  2.76249200e+138\n",
      "  6.64762028e+140 -4.07450735e+138  1.61241897e+138  3.15494960e+141\n",
      " -4.02617934e+138 -2.49247616e+141 -3.59638790e+139 -3.46701452e+141]\n",
      "Gradient Descent(66/100): loss = 1.0648645619056745e+291\n",
      "[ 1.87686685e+145 -9.74070264e+143 -6.76164545e+142  3.59368138e+143\n",
      " -3.31150639e+141 -3.30181304e+142  4.32425092e+143 -7.34374595e+141\n",
      "  2.06612109e+142 -3.65900393e+142  1.97005610e+140 -4.62360460e+140\n",
      " -1.11261772e+143  6.81953511e+140 -2.69871854e+140 -5.28046429e+143\n",
      "  6.73864810e+140  4.17167550e+143  6.01930200e+141  5.80276883e+143]\n",
      "Gradient Descent(67/100): loss = 2.9830030319769585e+295\n",
      "[-3.14132684e+147  1.63030911e+146  1.13170248e+145 -6.01477223e+145\n",
      "  5.54249576e+143  5.52627214e+144 -7.23753132e+145  1.22912864e+144\n",
      " -3.45808313e+144  6.12410670e+144 -3.29729848e+142  7.73856344e+142\n",
      "  1.86219739e+145 -1.14139097e+143  4.51686674e+142  8.83795503e+145\n",
      " -1.12785284e+143 -6.98216425e+145 -1.00745522e+144 -9.71213905e+145]\n",
      "Gradient Descent(68/100): loss = 8.356280607985827e+299\n",
      "[ 5.25766348e+149 -2.72866123e+148 -1.89414005e+147  1.00669709e+148\n",
      " -9.27652063e+145 -9.24936730e+146  1.21135113e+148 -2.05720242e+146\n",
      "  5.78782096e+146 -1.02499694e+147  5.51871452e+144 -1.29520946e+145\n",
      " -3.11677487e+147  1.91035507e+145 -7.55991578e+144 -1.47921554e+148\n",
      "  1.88769619e+145  1.16861009e+148  1.68618562e+146  1.62552825e+148]\n",
      "Gradient Descent(69/100): loss = inf\n",
      "[-8.79979279e+151  4.56698185e+150  3.17023800e+149 -1.68491675e+150\n",
      "  1.55261879e+148  1.54807416e+149 -2.02744768e+150  3.44315605e+148\n",
      " -9.68712152e+148  1.71554594e+149 -9.23671606e+146  2.16780227e+147\n",
      "  5.21657122e+149 -3.19737635e+147  1.26530910e+147  2.47577476e+150\n",
      " -3.15945199e+147 -1.95591161e+150 -2.82218201e+148 -2.72065931e+150]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(70/100): loss = inf\n",
      "[ 1.47282825e+154 -7.64379357e+152 -5.30605344e+151  2.82005832e+152\n",
      " -2.59863060e+150 -2.59102425e+151  3.39335485e+152 -5.76283760e+150\n",
      "  1.62134116e+151 -2.87132336e+151  1.54595646e+149 -3.62826773e+149\n",
      " -8.73101705e+151  5.35147400e+149 -2.11775786e+149 -4.14372379e+152\n",
      "  5.28799970e+149  3.27362429e+152  4.72350807e+150  4.55358874e+152]\n",
      "Gradient Descent(71/100): loss = inf\n",
      "[-2.46508425e+156  1.27934776e+155  8.88078486e+153 -4.71995367e+154\n",
      "  4.34934887e+152  4.33661812e+153 -5.67948436e+154  9.64530695e+152\n",
      " -2.71365147e+153  4.80575729e+153 -2.58747952e+151  6.07266028e+151\n",
      "  1.46131729e+154 -8.95680421e+151  3.54450809e+151  6.93538325e+154\n",
      " -8.85056676e+151 -5.47909028e+154 -7.90577243e+152 -7.62137712e+154]\n",
      "Gradient Descent(72/100): loss = inf\n",
      "[ 4.12583093e+158 -2.14125443e+157 -1.48638414e+156  7.89982344e+156\n",
      " -7.27953993e+154 -7.25823244e+155  9.50579721e+156 -1.61434265e+155\n",
      "  4.54185983e+155 -8.04343481e+155  4.33068487e+153 -1.01638593e+154\n",
      " -2.44581838e+156  1.49910738e+154 -5.93247119e+153 -1.16078057e+157\n",
      "  1.48132633e+154  9.17039595e+156  1.32319533e+155  1.27559586e+157]\n",
      "Gradient Descent(73/100): loss = inf\n",
      "[-6.90543572e+160  3.58383443e+159  2.48777307e+158 -1.32219965e+159\n",
      "  1.21838239e+157  1.21481615e+158 -1.59099271e+159  2.70193806e+157\n",
      " -7.60174658e+157  1.34623614e+158 -7.24830141e+155  1.70113315e+156\n",
      "  4.09358563e+158 -2.50906783e+156  9.92922387e+155  1.94280760e+159\n",
      " -2.47930755e+156 -1.53485632e+159 -2.21464241e+157 -2.13497481e+159]\n",
      "Gradient Descent(74/100): loss = inf\n",
      "[ 1.15576822e+163 -5.99829193e+161 -4.16380567e+160  2.21297594e+161\n",
      " -2.03921628e+159 -2.03324745e+160  2.66285695e+161 -4.52225507e+159\n",
      "  1.27231031e+160 -2.25320620e+160  1.21315392e+158 -2.84719995e+158\n",
      " -6.85146669e+160  4.19944660e+158 -1.66186204e+158 -3.25169240e+161\n",
      "  4.14963658e+158  2.56890101e+161  3.70666439e+159  3.57332411e+161]\n",
      "Gradient Descent(75/100): loss = inf\n",
      "[-1.93441837e+165  1.00393885e+164  6.96899472e+162 -3.70387522e+163\n",
      "  3.41305245e+161  3.40306238e+162 -4.45684455e+163  7.56893400e+161\n",
      " -2.12947579e+162  3.77120916e+162 -2.03046528e+160  4.76538098e+160\n",
      "  1.14673540e+163 -7.02864687e+160  2.78147160e+160  5.44238321e+163\n",
      " -6.94527944e+160 -4.29958973e+163 -6.20387333e+161 -5.98070066e+163]\n",
      "Gradient Descent(76/100): loss = inf\n",
      "[ 3.23765126e+167 -1.68030036e+166 -1.16640618e+165  6.19920508e+165\n",
      " -5.71245289e+163 -5.69573245e+164  7.45945570e+165 -1.26681845e+164\n",
      "  3.56412041e+164 -6.31190273e+164  3.39840573e+162 -7.97585569e+162\n",
      " -1.91930010e+165  1.17639016e+163 -4.65537095e+162 -9.10895968e+165\n",
      "  1.16243689e+163  7.19625705e+165  1.03834716e+164  1.00099457e+166]\n",
      "Gradient Descent(77/100): loss = inf\n",
      "[-5.41888243e+169  2.81233195e+168  1.95222327e+167 -1.03756583e+168\n",
      "  9.56097756e+165  9.53299244e+166 -1.24849496e+168  2.12028404e+166\n",
      " -5.96529641e+166  1.05642816e+167 -5.68793845e+164  1.33492525e+165\n",
      "  3.21234774e+167 -1.96893349e+165  7.79173106e+164  1.52457376e+168\n",
      " -1.94557978e+165 -1.20444319e+168 -1.73788981e+166 -1.67537250e+168]\n",
      "Gradient Descent(78/100): loss = inf\n",
      "[ 9.06962621e+171 -4.70702215e+170 -3.26745155e+169  1.73658210e+170\n",
      " -1.60022837e+168 -1.59554448e+169  2.08961583e+170 -3.54873611e+168\n",
      "  9.98416359e+168 -1.76815218e+169  9.51994741e+166 -2.23427491e+167\n",
      " -5.37653177e+169  3.29541949e+167 -1.30410817e+167 -2.55169112e+170\n",
      "  3.25633221e+167  2.01588603e+170  2.90871985e+168  2.80408413e+170]\n",
      "Gradient Descent(79/100): loss = inf\n",
      "[-1.51799048e+174  7.87818006e+172  5.46875949e+171 -2.90653113e+172\n",
      "  2.67831485e+170  2.67047539e+171 -3.49740645e+172  5.93954760e+170\n",
      " -1.67105732e+171  2.95937029e+171 -1.59336110e+169  3.73952351e+169\n",
      "  8.99874363e+171 -5.51556956e+169  2.18269612e+169  4.27078553e+172\n",
      " -5.45014887e+169 -3.37400430e+172 -4.86834732e+170 -4.69321769e+172]\n",
      "Gradient Descent(80/100): loss = inf\n",
      "[ 2.54067263e+176 -1.31857720e+175 -9.15310596e+173  4.86468403e+174\n",
      " -4.48271669e+172 -4.46959573e+173  5.85363670e+174 -9.94106763e+172\n",
      "  2.79686181e+173 -4.95312143e+173  2.66682102e+171 -6.25886996e+171\n",
      " -1.50612682e+174  9.23145222e+171 -3.65319570e+171 -7.14804740e+174\n",
      "  9.12195711e+171  5.64709754e+174  8.14819124e+172  7.85507540e+174]\n",
      "Gradient Descent(81/100): loss = inf\n",
      "[-4.25234380e+178  2.20691305e+177  1.53196257e+176 -8.14205997e+176\n",
      "  7.50275828e+174  7.48079763e+175 -9.79727782e+176  1.66384432e+175\n",
      " -4.68112964e+175  8.29007843e+175 -4.46347936e+173  1.04755200e+174\n",
      "  2.52081633e+176 -1.54507543e+174  6.11438242e+173  1.19637433e+177\n",
      " -1.52674915e+174 -9.45159159e+176 -1.36376918e+175 -1.31471016e+177]\n",
      "Gradient Descent(82/100): loss = inf\n",
      "[ 7.11718131e+180 -3.69372776e+179 -2.56405784e+178  1.36274299e+179\n",
      " -1.25574257e+177 -1.25206700e+178  1.63977810e+179 -2.78478936e+177\n",
      "  7.83484356e+177 -1.38751697e+178  7.47056057e+175 -1.75329603e+176\n",
      " -4.21911016e+178  2.58600492e+176 -1.02336900e+176 -2.00238114e+179\n",
      "  2.55533207e+176  1.58192032e+179  2.28255122e+177  2.20044074e+179]\n",
      "Gradient Descent(83/100): loss = inf\n",
      "[-1.19120824e+183  6.18222126e+181  4.29148383e+180 -2.28083367e+181\n",
      "  2.10174624e+179  2.09559441e+180 -2.74450952e+181  4.66092389e+179\n",
      " -1.31132394e+180  2.32229809e+180 -1.25035361e+178  2.93450537e+178\n",
      "  7.06155793e+180 -4.32821681e+178  1.71282077e+178  3.35140108e+181\n",
      " -4.27687942e+178 -2.64767250e+181 -3.82032396e+179 -3.68289500e+181]\n",
      "Gradient Descent(84/100): loss = inf\n",
      "[ 1.99373462e+185 -1.03472324e+184 -7.18269033e+182  3.81744929e+183\n",
      " -3.51770924e+181 -3.50741288e+182  4.59350720e+183 -7.80102503e+181\n",
      "  2.19477321e+182 -3.88684863e+182  2.09272668e+180 -4.91150476e+180\n",
      " -1.18189852e+183  7.24417057e+180 -2.86676161e+180 -5.60926640e+183\n",
      "  7.15824679e+180  4.43143031e+183  6.39410630e+181  6.16409037e+183]\n",
      "Gradient Descent(85/100): loss = inf\n",
      "[-3.33692934e+187  1.73182444e+186  1.20217254e+185 -6.38929494e+185\n",
      "  5.88761768e+183  5.87038457e+184 -7.68818917e+185  1.30566371e+184\n",
      " -3.67340921e+184  6.50544920e+184 -3.50261314e+182  8.22042421e+182\n",
      "  1.97815286e+185 -1.21246254e+183  4.79812149e+182  9.38827336e+185\n",
      " -1.19808140e+183 -7.41691980e+185 -1.07018661e+184 -1.03168866e+186]\n",
      "Gradient Descent(86/100): loss = inf\n",
      "[ 5.58504493e+189 -2.89856821e+188 -2.01208566e+187  1.06938133e+188\n",
      " -9.85415210e+185 -9.82530892e+186  1.28677828e+188 -2.18529963e+186\n",
      "  6.14821393e+186 -1.08882216e+187  5.86235120e+184 -1.37585888e+185\n",
      " -3.31085003e+187  2.02930810e+185 -8.03065374e+184 -1.57132271e+188\n",
      "  2.00523828e+185  1.24137571e+188  1.79117976e+186  1.72674544e+188]\n",
      "Gradient Descent(87/100): loss = inf\n",
      "[-9.34773369e+191  4.85135645e+190  3.36764363e+189 -1.78983195e+190\n",
      "  1.64929720e+188  1.64446970e+189 -2.15369094e+190  3.65755321e+188\n",
      " -1.02903141e+189  1.82237023e+189 -9.81186339e+186  2.30278584e+187\n",
      "  5.54139578e+189 -3.39646895e+187  1.34409684e+187  2.62993520e+190\n",
      " -3.35618311e+187 -2.07770030e+190 -2.99791167e+188 -2.89006744e+190]\n",
      "Gradient Descent(88/100): loss = inf\n",
      "[ 1.56453755e+194 -8.11975352e+192 -5.63645168e+191  2.99565583e+192\n",
      " -2.76044172e+190 -2.75236189e+191  3.60464949e+192 -6.12167562e+190\n",
      "  1.72229797e+191 -3.05011541e+191  1.64221931e+189 -3.85419080e+189\n",
      " -9.27467777e+191  5.68469684e+189 -2.24962548e+189 -4.40174326e+192\n",
      "  5.61727012e+189  3.47746336e+192  5.01762837e+190  4.83712864e+192]\n",
      "Gradient Descent(89/100): loss = inf\n",
      "[-2.61857883e+196  1.35900954e+195  9.43377359e+193 -5.01385277e+194\n",
      "  4.62017306e+192  4.60664978e+193 -6.03313024e+194  1.02458967e+193\n",
      " -2.88262369e+193  5.10500220e+193 -2.74859539e+191  6.45078951e+191\n",
      "  1.55231013e+194 -9.51452188e+191  3.76521588e+191  7.36723236e+194\n",
      " -9.40166924e+191 -5.82025782e+194 -8.39804414e+192 -8.09594031e+194]\n",
      "Gradient Descent(90/100): loss = inf\n",
      "[ 4.38273601e+198 -2.27458498e+197 -1.57893812e+196  8.39172488e+196\n",
      " -7.73282005e+194 -7.71018603e+195  1.00976976e+197 -1.71486381e+195\n",
      "  4.82466998e+195 -8.54428241e+195  4.60034576e+193 -1.07967372e+194\n",
      " -2.59811369e+196  1.59245302e+194 -6.30187148e+193 -1.23305948e+197\n",
      "  1.57356479e+194  9.74141135e+196  1.40558726e+195  1.35502391e+197]\n",
      "Gradient Descent(91/100): loss = inf\n",
      "[-7.33541979e+200  3.80699080e+199  2.64268117e+198 -1.40452960e+199\n",
      "  1.29424818e+197  1.29045991e+198 -1.69005960e+199  2.87018106e+197\n",
      " -8.07508815e+197  1.43006328e+198 -7.69963493e+195  1.80705841e+196\n",
      "  4.34848335e+198 -2.66530117e+196  1.05474919e+196  2.06378137e+199\n",
      " -2.63368778e+196 -1.63042769e+199 -2.35254247e+197 -2.26791419e+199]\n",
      "Gradient Descent(92/100): loss = inf\n",
      "[ 1.22773499e+203 -6.37179049e+201 -4.42307629e+200  2.35077226e+201\n",
      " -2.16619338e+199 -2.15985292e+200  2.82866607e+201 -4.80384465e+199\n",
      "  1.35153386e+200 -2.39350818e+200  1.28869396e+198 -3.02448790e+198\n",
      " -7.27809084e+200  4.46093556e+198 -1.76534204e+198 -3.45416714e+201\n",
      "  4.40802399e+198  2.72885967e+201  3.93746887e+199  3.79582584e+201]\n",
      "Gradient Descent(93/100): loss = inf\n",
      "[-2.05486972e+205  1.06645159e+204  7.40293764e+202 -3.93450605e+203\n",
      "  3.62557493e+201  3.61496285e+202 -4.73436069e+203  8.04023264e+201\n",
      " -2.26207288e+202  4.00603349e+202 -2.15689724e+200  5.06210923e+200\n",
      "  1.21813980e+203 -7.46630300e+200  2.95466687e+200  5.78126676e+203\n",
      " -7.37774448e+200 -4.56731393e+203 -6.59017267e+201 -6.35310362e+203]\n",
      "Gradient Descent(94/100): loss = inf\n",
      "[ 3.43925164e+207 -1.78492843e+206 -1.23903550e+205  6.58521378e+205\n",
      " -6.06815332e+203 -6.05039179e+204  7.92393678e+205 -1.34570007e+204\n",
      "  3.78604919e+204 -6.70492982e+204  3.61001590e+202 -8.47249210e+202\n",
      " -2.03881018e+205  1.24964101e+203 -4.94524922e+202 -9.67615172e+205\n",
      "  1.23481891e+203  7.64434930e+205  1.10300239e+204  1.06332396e+206]\n",
      "Gradient Descent(95/100): loss = inf\n",
      "[-5.75630257e+209  2.98744878e+208  2.07378349e+207 -1.10217242e+208\n",
      "  1.01563160e+206  1.01265884e+207 -1.32623554e+208  2.25230881e+206\n",
      " -6.33674036e+206  1.12220939e+207 -6.04211206e+204  1.41804768e+205\n",
      "  3.41237265e+207 -2.09153401e+205  8.27690258e+204  1.61950514e+208\n",
      " -2.06672613e+205 -1.27944076e+208 -1.84610379e+206 -1.77969368e+208]\n",
      "Gradient Descent(96/100): loss = inf\n",
      "[ 9.63436896e+211 -5.00011656e+210 -3.47090776e+209  1.84471466e+210\n",
      " -1.69987061e+208 -1.69489508e+209  2.21973087e+210 -3.76970700e+208\n",
      "  1.06058523e+209 -1.87825069e+209  1.01127305e+207 -2.37339757e+207\n",
      " -5.71131499e+209  3.50061695e+207 -1.38531171e+207 -2.71057850e+210\n",
      "  3.45909580e+207  2.14141009e+210  3.08983846e+208  2.97868734e+210]\n",
      "Gradient Descent(97/100): loss = inf\n",
      "[-1.61251192e+214  8.36873448e+212  5.80928566e+211 -3.08751346e+212\n",
      "  2.84508684e+210  2.83675925e+211 -3.71518105e+212  6.30938830e+210\n",
      " -1.77510985e+211  3.14364298e+211 -1.69257568e+209  3.97237421e+209\n",
      "  9.55907289e+211 -5.85901017e+209  2.31860712e+209  4.53671660e+212\n",
      " -5.78951590e+209 -3.58409493e+212 -5.17148697e+210 -4.98545247e+212]\n",
      "Gradient Descent(98/100): loss = inf\n",
      "[ 2.69887391e+216 -1.40068168e+215 -9.72304717e+213  5.16759559e+214\n",
      " -4.76184425e+212 -4.74790630e+213  6.21812779e+214 -1.05600729e+213\n",
      "  2.97101534e+213 -5.26154002e+213  2.83287725e+211 -6.64859400e+211\n",
      " -1.59990956e+214  9.80627147e+211 -3.88067100e+211 -7.59313831e+214\n",
      "  9.68995837e+211  5.99872792e+214  8.65555848e+212  8.34419107e+214]\n",
      "Gradient Descent(99/100): loss = inf\n",
      "[-4.51712652e+218  2.34433197e+217  1.62735407e+216 -8.64904545e+216\n",
      "  7.96993624e+214  7.94660818e+215 -1.04073295e+217  1.76744772e+215\n",
      " -4.97261178e+215  8.80628097e+215 -4.74140896e+213  1.11278042e+214\n",
      "  2.67778124e+216 -1.64128338e+214  6.49510962e+213  1.27086954e+217\n",
      " -1.62181597e+214 -1.00401182e+217 -1.44868764e+215 -1.39657383e+217]\n"
     ]
    }
   ],
   "source": [
    "from general_helper import *\n",
    "\n",
    "def least_squares_GD(y, tX, initial_w, max_iters, gamma):\n",
    "    '''implementing the linear regression with gradient descent'''\n",
    "    w = initial_w\n",
    "    \n",
    "    for n_iter in range(max_iters):\n",
    "        l = compute_mse(y, tX, w)\n",
    "        g = compute_gradient(y, tX, w)\n",
    "        w = w - gamma * g\n",
    "        \n",
    "    return l, w\n",
    "\n",
    "max_iters = 100\n",
    "gamma = 0.001\n",
    "initial_w = np.zeros((tX.shape[1],))\n",
    "print(initial_w)\n",
    "loss, weight = least_squares_GD(y, tX, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'prediction' # TODO: fill in desired name of output file for submission\n",
    "tX_test = np.delete(tX_test, [4,5,6,12,23,24,25,26,27,28], axis=1)\n",
    "y_pred = predict_labels(weight, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
